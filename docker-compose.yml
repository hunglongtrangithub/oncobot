version: "3.8"

services:
  chat-frontend:
    build:
      context: ./chat-langchain
      dockerfile: Dockerfile
    container_name: chat-frontend

    working_dir: /app
    command: yarn dev
    volumes:
      - ./chat-langchain:/app
      - /app/node_modules

    ports:
      - 3000:3000
    environment:
      - NEXT_PUBLIC_API_BASE_URL=http://localhost:8080

  chat-backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: chat-backend

    working_dir: /app
    entrypoint: /bin/bash -c
    command: "./expect.exp && uvicorn main:app --host 0.0.0.0 --port 8080 --reload"

    volumes:
      - .:/app
      - ./faiss_index:/app/faiss_index
      - ./llm_llama:/app/llm_llama
      - ./voices:/app/voices

    ports:
      - 8080:8080
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - REPLICATE_API_TOKEN=${REPLICATE_API_TOKEN}
      - GROQ_API_KEY=${GROQ_API_KEY}

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 4
              capabilities: [gpu]
